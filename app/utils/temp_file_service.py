import hashlib
import time
from contextlib import contextmanager
from datetime import datetime
from pathlib import Path

from app.config import FileConfig
from app.core.exception import ValidationError, logger, FileUploadError, RedisConnectionError, FileSaveError, \
    NotFoundError, FileCleanupError
from app.core.redis_connection_pool import redis_pool
from app.docker.core.celery_app import CeleryManager
from app.exts import db
from app.model.model_service import ModelService
from app.user.user_service import UserService
from app.utils.image_url_utils import ImageURLHandlerUtils
from app.utils.storage import storage, FileStorage


def remove_empty_parents_safely(file_path: Path, stop_at: Path, max_retries: int = 3):
    """
    å®‰å…¨åˆ é™¤ç©ºç›®å½•é“¾ï¼ˆå¸¦å¹¶å‘æ£€æŸ¥å’Œé‡è¯•æœºåˆ¶ï¼‰

    å‚æ•°:
        file_path: è¢«åˆ é™¤æ–‡ä»¶çš„è·¯å¾„
        stop_at: åœæ­¢åˆ é™¤çš„çˆ¶ç›®å½•ï¼ˆåŒ…å«è¯¥ç›®å½•æœ¬èº«ï¼‰
        max_retries: ç›®å½•æ“ä½œæœ€å¤§é‡è¯•æ¬¡æ•°
    """
    # if not file_path.is_relative_to(Path(FileConfig.TEMP_DIR).resolve()):
    #     logger.warning(f"âš ï¸ æ‹’ç»å¤„ç†éä¸´æ—¶ç›®å½•: {file_path}")
    #     return

    current_dir = file_path.parent

    while current_dir != stop_at and current_dir.is_relative_to(stop_at):
        logger.debug(f"â–¶ å¼€å§‹å¤„ç†ç›®å½•: {current_dir}")

        # é‡è¯•æœºåˆ¶åº”å¯¹çŸ­æš‚çš„æ–‡ä»¶ç³»ç»Ÿå»¶è¿Ÿ
        for attempt in range(max_retries):
            try:
                if not any(current_dir.iterdir()):
                    logger.debug(f"â†˜ å°è¯•åˆ é™¤ç©ºç›®å½•ï¼ˆç¬¬{attempt + 1}æ¬¡å°è¯•ï¼‰: {current_dir}")
                    current_dir.rmdir()
                    logger.info(f"ğŸ—‘ï¸ æˆåŠŸåˆ é™¤ç©ºç›®å½•: {current_dir}")
                    break
                else:
                    logger.warning(f"âš ï¸ ç›®å½•éç©ºï¼Œåœæ­¢å‘ä¸Šåˆ é™¤: {current_dir}")
                    return
            except FileNotFoundError:
                logger.debug(f"â†— ç›®å½•å·²è¢«å…¶ä»–è¿›ç¨‹åˆ é™¤: {current_dir}")
                break
            except PermissionError as e:
                logger.error(f"â›” ç›®å½•æƒé™é”™è¯¯: {current_dir} - {str(e)}")
                return
            except OSError as e:
                if attempt == max_retries - 1:
                    logger.warning(f"âš ï¸ åˆ é™¤ç›®å½•å¤±è´¥ï¼ˆå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰: {current_dir} - {str(e)}")
                    return
                logger.debug(f"â†» é‡åˆ°æš‚æ—¶æ€§é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•: {current_dir} - {str(e)}")
                time.sleep(0.5 * (attempt + 1))
        else:
            return

        # å‘ä¸Šç§»åŠ¨ä¸€çº§ç›®å½•ï¼ˆä½¿ç”¨è§£æåçš„ç»å¯¹è·¯å¾„é¿å…ç¬¦å·é“¾æ¥é—®é¢˜ï¼‰
        parent_dir = current_dir.resolve().parent
        if parent_dir == current_dir.resolve():
            logger.debug("â¹ åˆ°è¾¾æ ¹ç›®å½•ï¼Œåœæ­¢å¤„ç†")
            break
        current_dir = parent_dir


class TempFileService:
    def __init__(self):
        self.storage = storage
        self.redis = redis_pool

    @staticmethod
    @contextmanager
    def _get_redis_conn():
        """å¤ç”¨Redisè¿æ¥ç®¡ç†"""
        with redis_pool.get_redis_connection('files') as conn:
            yield conn

    @staticmethod
    def _cleanup_temp_files(src_file: Path, is_temp: bool = True):
        """åŸå­åŒ–æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if src_file.exists():
                src_file.unlink(missing_ok=True)
                # æ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½® stop_at
                stop_at = (
                    Path(FileConfig.TEMP_DIR).resolve()
                    if is_temp
                    else Path(FileConfig.FORMAL_RIR).resolve()
                )
                remove_empty_parents_safely(
                    file_path=src_file,
                    stop_at=stop_at,
                    max_retries=3
                )
        except Exception as e:
            logger.error(f"æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
            raise FileCleanupError("æ–‡ä»¶æ¸…ç†å¤±è´¥")  # è‡ªå®šä¹‰å¼‚å¸¸

    @staticmethod
    def _update_redis_status(redis_key: str, error: Exception = None):
        """æ›´æ–°RedisçŠ¶æ€"""
        try:
            with redis_pool.get_redis_connection('files') as conn:
                if isinstance(error, FileNotFoundError):
                    conn.delete(redis_key)
                elif error:
                    conn.hset(redis_key, "status", "error")
                else:
                    conn.delete(redis_key)
        except Exception as e:
            logger.error(f"RedisçŠ¶æ€æ›´æ–°å¤±è´¥: {e}")

    def save_temp(self, file, upload_type: str, data_id: int, file_type: str, user_id: int) -> str:
        """ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•å¹¶ç”ŸæˆURL"""
        try:
            # ç”Ÿæˆæ–‡ä»¶å“ˆå¸Œï¼ˆä½¿ç”¨æ–‡ä»¶å†…å®¹ï¼‰
            logger.info(f"upload_type: {upload_type}, file_type: {file_type}, data_id: {data_id}, file: {file}")

            # ========== æ–‡ä»¶å†…å®¹å¤„ç† ==========
            try:
                file_content = file.read()
                file_hash = hashlib.md5(file_content).hexdigest()
                file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            except IOError as e:
                logger.error("æ–‡ä»¶è¯»å–å¤±è´¥: %s", e)
                raise FileUploadError("æ–‡ä»¶æŸåæˆ–æ— æ³•è¯»å–")

            logger.info(f"âœ… è®¡ç®—çš„æ–‡ä»¶å“ˆå¸Œ: {file_hash}")
            logger.info(f"âœ… ä¿å­˜çš„æ–‡ä»¶å: {file_hash}{Path(file.filename).suffix}")

            # ========== Redisé‡å¤æ£€æŸ¥ ==========
            version = datetime.now().strftime("%Y%m%d%H%M%S")
            redis_key = f"temp:{user_id}:{upload_type}:{data_id}:{file_type}:{version}:{file_hash}"
            try:
                with self.redis.get_redis_connection('files') as conn:
                    if conn.exists(redis_key):
                        current_status = conn.hget(redis_key, "status")
                        if current_status:
                            if current_status in ['pending', 'processing']:
                                raise FileUploadError("æ–‡ä»¶å·²ä¸Šä¼ ï¼Œè¯·å‹¿é‡å¤æäº¤")
            except RedisConnectionError as e:
                logger.error("Redisè¿æ¥å¼‚å¸¸: %s", e)
                raise FileUploadError("ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åå†è¯•")

            # ========== ä¸´æ—¶ç›®å½•æ„å»º ==========
            try:
                 temp_dir = Path(FileConfig.TEMP_DIR) / FileConfig.UPLOAD_CONFIG[upload_type]['subdirectory'].format(
                    file_type=file_type,
                    data_id=data_id,
                    user_id=user_id,
                    version=version
                )
            except KeyError:
                logger.error("æ— æ•ˆçš„ä¸Šä¼ ç±»å‹: %s", upload_type)
                raise FileUploadError("ä¸æ”¯æŒçš„ä¸Šä¼ ç±»å‹")

            # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
            # ========== æ–‡ä»¶å­˜å‚¨ ==========
            try:
                saved_path = self.storage.save_upload(
                    file_stream=file,
                    save_dir=temp_dir,
                    file_name=f"{file_hash}{Path(file.filename).suffix}"
                )
                saved_file_path = Path(saved_path) / f"{file_hash}{Path(file.filename).suffix}"
            except FileSaveError as e:
                logger.error("æ–‡ä»¶å­˜å‚¨å¤±è´¥: %s", e)
                raise FileUploadError("æ–‡ä»¶ä¿å­˜å¤±è´¥")
            logger.info(f"ä¸´æ—¶ä¿å­˜ç›®å½•: {saved_path}")
            logger.info(f"âœ… å®Œæ•´æ–‡ä»¶è·¯å¾„: {saved_file_path}")

            # ========== Redisè®°å½• ==========
            try:
                with self.redis.get_redis_connection('files') as conn:
                    conn.hmset(redis_key, {
                        "real_path": str(saved_file_path),
                        "user_id": user_id,
                        "status": "pending",
                        "expire_at": time.time() + 43200
                    })
                    # conn.expire(key, 120)  # åŸä¸º7å¤©ï¼ˆ604800ç§’ï¼‰
            except Exception as e:
                logger.error("Redisè®°å½•å¤±è´¥: %s", e)
                # å›æ»šå·²ä¿å­˜æ–‡ä»¶
                try:
                    saved_file_path.unlink(missing_ok=True)
                    remove_empty_parents_safely(saved_file_path, Path(FileConfig.TEMP_DIR))
                except Exception as cleanup_err:
                    logger.error("æ–‡ä»¶å›æ»šå¤±è´¥: %s", cleanup_err)
                raise FileUploadError("ç³»ç»Ÿä¸´æ—¶é”™è¯¯")

            logger.info(f"âœ… ä¿å­˜åˆ°Redisçš„é”®: {redis_key}")
            logger.info(f"âœ… æ–‡ä»¶å“ˆå¸Œ: {file_hash}")
            logger.info(f"âœ… ä¿å­˜è·¯å¾„: {saved_path}")

            # è·å–ç›¸å¯¹äº TEMP_DIR çš„è·¯å¾„
            relative_path = Path(saved_path).relative_to(FileConfig.TEMP_DIR)

            # ç”ŸæˆURLè·¯å¾„ï¼ˆä½¿ç”¨å®é™…å­˜å‚¨è·¯å¾„ç»“æ„ï¼‰
            url_path = f"{FileConfig.TEMP_BASE_URL}/{relative_path}/{file_hash}{Path(file.filename).suffix}"
            logger.info(f"âœ… ç”Ÿæˆçš„URLç›¸å¯¹è·¯å¾„: {url_path}")

            return url_path
        except FileUploadError:
            raise
        except Exception as e:
            logger.error("æœªçŸ¥å¼‚å¸¸", exc_info=True)
            raise FileUploadError("ä¸Šä¼ æœåŠ¡å¼‚å¸¸")  # å…œåº•å¼‚å¸¸å¤„ç†

    def commit_from_temp(self, temp_url: str, user_id: int) -> bool:
        """ä»ä¸´æ—¶URLæäº¤æ–‡ä»¶ï¼ˆå…¶ä»–æ¥å£è°ƒç”¨ï¼‰"""
        # è§£æURLå‚æ•°
        try:
            # ä½¿ç”¨å·¥å…·ç±»éªŒè¯å’Œè§£æURL
            ImageURLHandlerUtils.validate_photo_file(temp_url)
            url_components = ImageURLHandlerUtils.parse_temp_url_components(temp_url)
            redis_key = ImageURLHandlerUtils.build_temp_redis_key(url_components)

            # è®°å½•è°ƒè¯•æ—¥å¿—
            logger.debug(f"è§£æç»“æœ: {url_components}")

            # RediséªŒè¯
            with self.redis.get_redis_connection('files') as conn:
                file_info = conn.hgetall(redis_key)
                logger.debug(f"Redisè¿”å›æ•°æ®: {file_info} | ç±»å‹: {type(file_info)}")

                if not isinstance(file_info, dict):
                    logger.error(f"Redisæ•°æ®æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›å­—å…¸ï¼Œå®é™…å¾—åˆ°: {type(file_info)}")
                    raise ValidationError("æ–‡ä»¶å…ƒæ•°æ®æŸå")

                if not file_info:
                    logger.error(f"Redisé”®ä¸å­˜åœ¨: {redis_key}")
                    raise ValidationError("æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ")

                if 'user_id' not in file_info:
                    logger.error(f"Redisè®°å½•ç¼ºå°‘user_idå­—æ®µ: {file_info}")
                    raise ValidationError("æ–‡ä»¶å…ƒæ•°æ®ä¸å®Œæ•´")

                if file_info.get('user_id') != str(user_id):
                    logger.warning(
                        f"ç”¨æˆ·æƒé™éªŒè¯å¤±è´¥: Redis.user_id={file_info.get('user_id')} vs Current.user_id={user_id}")
                    raise ValidationError("æ— æ“ä½œæƒé™")

                if file_info.get('status') == 'committed':
                    logger.warning(f"æ–‡ä»¶é‡å¤æäº¤: {redis_key}")
                    raise ValidationError("æ–‡ä»¶å·²æäº¤")

                # æ›´æ–°çŠ¶æ€
                conn.hset(redis_key, "status", "processing")
                logger.info(f"çŠ¶æ€æ›´æ–°ä¸ºprocessing: {redis_key}")

            # å¼‚æ­¥è½¬ç§»æ–‡ä»¶
            self._move_to_final.delay(
                redis_key=redis_key,
                src_path=file_info['real_path'],
                upload_type=url_components['upload_type'],
                data_id=url_components['data_id'],
                file_type=url_components['file_type'],
                user_id=user_id,
                version=url_components['version']
            )
            logger.info(f"âœ… è§£æå¾—åˆ°çš„å‚æ•°: {url_components}")
            logger.info(f"âœ… ç”Ÿæˆçš„Redisé”®: {redis_key}")

            return True
        except ValidationError as e:
            logger.error("æ–‡ä»¶éªŒè¯å¤±è´¥ï¼š%s", str(e))
            raise e
        except Exception as e:
            logger.error("æäº¤æ–‡ä»¶æ—¶å‘ç”Ÿæœªæ•è·çš„å¼‚å¸¸: %s", str(e))
            raise e

    @staticmethod
    @CeleryManager.get_celery().task(bind=True, expires=86400)
    def _move_to_final(self, redis_key: str, src_path: str, upload_type: str, data_id: int, file_type: str,
                       user_id: int, version: str) -> None:
        """åŸå­åŒ–æ–‡ä»¶è½¬ç§»æ“ä½œï¼ˆå¢å¼ºå¥å£®æ€§ï¼‰"""
        src_file = Path(src_path)
        final_file_path = None
        error = None

        try:
            src_file = Path(src_path)
            # ========== 1. åˆå§‹åŒ–æ£€æŸ¥ ==========
            from myapp import create_app
            app = create_app()  # åˆ›å»ºFlaskä¸Šä¸‹æ–‡

            # ========== 2. å‰ç½®çŠ¶æ€éªŒè¯ ==========
            with redis_pool.get_redis_connection('files') as conn:
                # æ£€æŸ¥Redisé”®æ˜¯å¦å­˜åœ¨ï¼Œé˜²æ­¢é‡å¤å¤„ç†
                if not conn.exists(redis_key):
                    logger.warning(f"â© è·³è¿‡å·²å¤„ç†çš„ä»»åŠ¡: {redis_key}")
                    return

                # è·å–æ–‡ä»¶ä¿¡æ¯
                file_info = conn.hgetall(redis_key)
                if file_info.get('status') == 'committed':
                    logger.warning(f"â© æ–‡ä»¶å·²æäº¤: {redis_key}")
                    return

                # æ ‡è®°ä¸ºå¤„ç†ä¸­ï¼ˆé˜²æ­¢å¹¶å‘ï¼‰
                conn.hset(redis_key, "status", "processing")

            # ========== 3. æ–‡ä»¶æ“ä½œ ==========
            if not src_file.exists():
                logger.error(f"â›” æºæ–‡ä»¶ä¸å­˜åœ¨: {src_path}")
                with redis_pool.get_redis_connection('files') as conn:
                    conn.delete(redis_key)  # æ¸…ç†æ— æ•ˆé”®
                return

            # 3.1 ç§»åŠ¨æ–‡ä»¶åˆ°æ­£å¼ç›®å½•
            # æ„å»ºæ­£å¼ç›®å½•
            final_subdir = FileConfig.UPLOAD_CONFIG[upload_type]['subdirectory'].format(
                file_type=file_type,
                data_id=data_id,
                user_id=user_id,
                version=version
            )
            final_dir = Path(FileConfig.LOCAL_FILE_BASE) / "user_data" / final_subdir
            final_dir.mkdir(parents=True, exist_ok=True)
            final_file_path = final_dir / src_file.name

            # ä½¿ç”¨æ–‡ä»¶æµé¿å…å ç”¨æ–‡ä»¶é”
            with open(src_path, 'rb') as src_stream:
                FileStorage.save_upload(
                    file_stream=src_stream,
                    save_dir=final_dir,
                    file_name=src_file.name
                )

            # ========== 4. æ•°æ®åº“æ›´æ–° ==========
            relative_path = str(final_file_path.relative_to(FileConfig.LOCAL_FILE_BASE))
            logger.info("æ–°æ–‡ä»¶å­˜æ”¾ç›¸å¯¹è·¯å¾„: %s", relative_path)

            database_mapping = {
                "model": {
                    "icon": (ModelService.get_model_by_id, "icon")  # (æ¨¡å‹æŸ¥è¯¢æ–¹æ³•, å­—æ®µå)
                },
                "user": {
                    "avatars": (UserService.get_user_by_id, "avatar")
                }
            }

            # åœ¨åº”ç”¨ä¸Šä¸‹æ–‡ä¸­æ›´æ–°æ•°æ®åº“
            with app.app_context():
                db_committed = False
                try:
                    # æ›´æ–°æ•°æ®åº“
                    if upload_type in database_mapping and file_type in database_mapping[upload_type]:
                        get_func, field = database_mapping[upload_type][file_type]
                        instance = get_func(data_id)

                        old_relative_path = getattr(instance, field)
                        logger.info("æ—§æ–‡ä»¶å­˜æ”¾ç›¸å¯¹è·¯å¾„ï¼š%s", old_relative_path)

                        # æ›´æ–°æ•°æ®åº“
                        setattr(instance, field, relative_path)
                        db.session.commit()
                        db_committed = True

                        # è·å–æ—§è·¯å¾„å¹¶åˆ é™¤å¯¹åº”çš„æ–‡ä»¶
                        if file_type in FileConfig.SINGLE_FILE_TYPES:
                            if old_relative_path:
                                old_file = Path(FileConfig.LOCAL_FILE_BASE) / old_relative_path
                                if old_file.exists():
                                    try:
                                        TempFileService._cleanup_temp_files(old_file, is_temp=False)
                                        logger.info("ğŸ—‘ï¸ åˆ é™¤æ—§æ–‡ä»¶: %s", old_file)
                                    except Exception as e:
                                        logger.error("â›” æ—§æ–‡ä»¶åˆ é™¤å¤±è´¥: %s", str(e))

                except Exception as e:
                    error = e
                    db.session.rollback()
                    logger.error("â›” æ•°æ®åº“æ›´æ–°å¤±è´¥: %s", str(e))

            TempFileService._update_redis_status(redis_key)

        except FileNotFoundError as e:
            error = e
            # 6. æ–‡ä»¶ä¸å­˜åœ¨æ—¶çš„ä¸“ç”¨å¤„ç†
            logger.error(f"ğŸ›‘ æ–‡ä»¶å·²åˆ é™¤ï¼Œç»ˆæ­¢ä»»åŠ¡: {src_path}")
            with redis_pool.get_redis_connection('files') as conn:
                conn.delete(redis_key)  # ç¡®ä¿æ¸…ç†æ®‹ç•™
            return  # ç›´æ¥è¿”å›ï¼Œä¸é‡è¯•
        except Exception as e:
            error = e
            # 7. å…¶ä»–é”™è¯¯å¤„ç†
            logger.error(f"è¿ç§»å¤±è´¥: {str(e)}")
            with redis_pool.get_redis_connection('files') as conn:
                conn.hset(redis_key, "status", "error")
            raise self.retry(exc=e, countdown=60, max_retries=2)  # æœ‰é™é‡è¯•
        finally:
            # ========== ç¡®ä¿æœ€ç»ˆæ¸…ç† ==========
            # æ— è®ºæˆåŠŸä¸å¦ï¼Œéƒ½å°è¯•æ¸…ç†ä¸´æ—¶æ–‡ä»¶åŠç›®å½•
            TempFileService._cleanup_temp_files(src_file, is_temp=True)

            # å¦‚æœæ–°æ–‡ä»¶å·²åˆ›å»ºå¹¶æœªæäº¤åˆ°æ•°æ®åº“ä¸­ä¸”ä»»åŠ¡å¤±è´¥ï¼Œæ¸…ç†æ–°æ–‡ä»¶
            if error and final_file_path and final_file_path.exists() and not db_committed:
                try:
                    logger.info("å›æ»šåˆ é™¤æ–°æ–‡ä»¶: %s", final_file_path)
                    TempFileService._cleanup_temp_files(final_file_path, is_temp=False)
                except Exception as e:
                    logger.error("æ–°æ–‡ä»¶æ¸…ç†å¤±è´¥: %s", str(e))


temp_service = TempFileService()


@CeleryManager.get_celery().task(bind=True, expires=86400)
def cleanup_temp_files(self):
    logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œä¸´æ—¶æ–‡ä»¶æ¸…ç†ä»»åŠ¡")
    try:
        with redis_pool.get_redis_connection('files') as conn:
            cursor = '0'
            deleted_count = 0
            total_scanned = 0  # ç»Ÿè®¡æ‰«æçš„é”®æ•°é‡
            while True:
                cursor, keys = conn.scan(cursor, match='temp:*', count=100)
                logger.info(f"ğŸ” æ‰«æåˆ° {len(keys)} ä¸ªé”®ï¼Œcursor={cursor}")  # æ–°å¢æ—¥å¿—
                total_scanned += len(keys)
                if not keys and cursor == 0:  # é€€å‡ºæ¡ä»¶ï¼šæ— é”®ä¸”æ¸¸æ ‡å½’é›¶
                    break

                for key in keys:
                    try:
                        # ç¡®ä¿æ¯æ¬¡å¾ªç¯éƒ½åˆå§‹åŒ–å˜é‡
                        file_path_str = None
                        file_path_obj = None

                        expire_at = conn.hget(key, 'expire_at')
                        file_path_str = conn.hget(key, 'real_path')
                        logger.debug(f"æ£€æŸ¥é”®: {key}, expire_at={expire_at}")
                        # æ¡ä»¶åˆ¤æ–­å’Œè·¯å¾„è½¬æ¢
                        if expire_at and float(expire_at) < time.time():
                            if file_path_str:
                                file_path_obj = Path(file_path_str)
                                logger.debug(f"å¤„ç†è¿‡æœŸé”®: {key}, æ–‡ä»¶è·¯å¾„={file_path_obj}")

                                # åˆ é™¤æ–‡ä»¶
                                if file_path_obj.exists() and file_path_obj.is_file():
                                    file_path_obj.unlink()
                                    logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {file_path_obj}")

                                    # æ¸…ç†ç©ºç›®å½•ï¼ˆæ¯æ¬¡åˆ é™¤æ–‡ä»¶åç«‹å³æ‰§è¡Œï¼‰
                                    remove_empty_parents_safely(
                                        file_path=file_path_obj,
                                        stop_at=Path(FileConfig.TEMP_DIR).resolve(),
                                        max_retries=2
                                    )
                                else:
                                    logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨æˆ–éæ–‡ä»¶: {file_path_obj}")

                            # åˆ é™¤ Redis é”®
                            conn.delete(key)
                            deleted_count += 1
                            logger.info(f"âœ… æ¸…ç†å®Œæˆ: {key}")

                    except Exception as e:
                        logger.error(f"æ¸…ç†å¤±è´¥: {key} - {str(e)}", exc_info=True)

                if cursor == 0:  # æ¸¸æ ‡å½’é›¶æ—¶é€€å‡º
                    break

            logger.info(f"ğŸ‰ æ¸…ç†å®Œæˆï¼Œå…±æ‰«æ {total_scanned} ä¸ªé”®ï¼Œåˆ é™¤ {deleted_count} ä¸ªè¿‡æœŸæ–‡ä»¶")

    except Exception as e:
        logger.error("æ¸…ç†ä»»åŠ¡å‘ç”Ÿå…¨å±€é”™è¯¯: %s", str(e), exc_info=True)
        raise self.retry(exc=e, countdown=300, max_retries=3)
